# ================================
# nginx/app.conf  (HTTP reverse proxy for NestJS)
# - Fronts the API running in the "api" container on port 3000
# - Only NGINX is exposed to the internet; API/DB stay private
# ================================

# ---- Rate limit state (HTTP-level) ----
# One "bucket" of counters keyed by client IP (binary form), stored in 10MB of shared memory.
# Limit to 100 requests per minute per IP.
limit_req_zone $binary_remote_addr zone=perip:10m rate=100r/m;

# ---- Upstream to our API container ----
# Docker's internal DNS lets "api" resolve to the API container.
# keepalive keeps TCP connections open to the upstream for speed.
upstream api_upstream {
    server api:3000;
    keepalive 64;
}

server {
    # Listen on plain HTTP. (TLS comes later with a separate 443 server block.)
    listen 80 default_server;
    server_name _;  # Catch-all

    # ------------ Performance: gzip ------------
    gzip on;
    gzip_min_length 1024;  # only compress if bigger than 1KB
    gzip_comp_level 5;     # sensible default (1-9, higher = more CPU)
    gzip_types
        text/plain
        text/css
        text/javascript
        application/json
        application/javascript
        application/xml
        application/xml+rss
        image/svg+xml;

    # ------------ Safety & timeouts ------------
    client_max_body_size 10m;  # allow request bodies (uploads) up to ~10MB
    keepalive_timeout 65s;     # how long NGINX keeps client TCP connections open
    proxy_read_timeout 60s;    # how long NGINX waits for the API to send a response
    proxy_send_timeout 60s;    # how long NGINX waits when sending data to the API
    proxy_connect_timeout 5s;  # how long to wait when opening a connection to the API

    # ------------ Health endpoint ------------
    # We make /health lightweight and *not* rate limited so external monitors can ping freely.
    location /health {
        # No request limiting for health checks
        # (Equivalent to not applying "limit_req" here.)
        proxy_pass http://api_upstream/health;

        # Use HTTP/1.1 + keepalive towards upstream
        proxy_http_version 1.1;
        proxy_set_header Connection "";

        # Forward original client details to the API (helps with logs & auth)
        proxy_set_header Host              $host;
        proxy_set_header X-Real-IP         $remote_addr;
        proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # ------------ Everything else ------------
    location / {
        # Apply the 100 req/min per IP with a small "burst" allowance.
        # burst=50 lets short spikes pass; nodelay processes immediately (excess gets 429).
        limit_req zone=perip burst=50 nodelay;

        proxy_pass http://api_upstream;

        # Keep connections to the API warm (fewer TCP handshakes)
        proxy_http_version 1.1;
        proxy_set_header Connection "";

        # Forward original client details
        proxy_set_header Host              $host;
        proxy_set_header X-Real-IP         $remote_addr;
        proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
